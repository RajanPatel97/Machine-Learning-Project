{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Read in white wine data \n",
    "white = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep=';')\n",
    "\n",
    "# Read in red wine data \n",
    "red = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add `type` column to `red` with value 1\n",
    "red['type'] = 1\n",
    "\n",
    "# Add `type` column to `white` with value 0\n",
    "white['type'] = 0\n",
    "\n",
    "# Append `white` to `red`\n",
    "wines = red.append(white, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wines.quality\n",
    "X = wines.drop(['quality', 'residual sugar', 'free sulfur dioxide', 'type'], axis=1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=46, stratify=y)\n",
    "\n",
    "# Define the scaler \n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Scale the train set\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "# Scale the test set\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras import layers, optimizers, regularizers\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras import metrics\n",
    "\n",
    "from keras.utils import plot_model\n",
    "#from kt_utils import *\n",
    "import keras.backend as K\n",
    "from sklearn import preprocessing, model_selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    # layer 1\n",
    "    model.add(Dense(9, input_dim=9, activation='relu', kernel_initializer='normal') )\n",
    "    #layer 2\n",
    "    model.add(Dense(50, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    #layer 4\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer = 'adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [100,150,200,250,300]\n",
    "epochs = [5,10,20,40,60,80,100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.524971 using {'batch_size': 150, 'epochs': 100}\n",
      "3.835788 (0.273399) with: {'batch_size': 100, 'epochs': 5}\n",
      "0.590092 (0.015708) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.542204 (0.025895) with: {'batch_size': 100, 'epochs': 20}\n",
      "0.537734 (0.017699) with: {'batch_size': 100, 'epochs': 40}\n",
      "0.538312 (0.026126) with: {'batch_size': 100, 'epochs': 60}\n",
      "0.532193 (0.026882) with: {'batch_size': 100, 'epochs': 80}\n",
      "0.533091 (0.030598) with: {'batch_size': 100, 'epochs': 100}\n",
      "12.296338 (0.571732) with: {'batch_size': 150, 'epochs': 5}\n",
      "0.798112 (0.108152) with: {'batch_size': 150, 'epochs': 10}\n",
      "0.571611 (0.035491) with: {'batch_size': 150, 'epochs': 20}\n",
      "0.545635 (0.018262) with: {'batch_size': 150, 'epochs': 40}\n",
      "0.546828 (0.030945) with: {'batch_size': 150, 'epochs': 60}\n",
      "0.537868 (0.018149) with: {'batch_size': 150, 'epochs': 80}\n",
      "0.524971 (0.030906) with: {'batch_size': 150, 'epochs': 100}\n",
      "18.795101 (1.557046) with: {'batch_size': 200, 'epochs': 5}\n",
      "3.192097 (0.397795) with: {'batch_size': 200, 'epochs': 10}\n",
      "0.572600 (0.037726) with: {'batch_size': 200, 'epochs': 20}\n",
      "0.543167 (0.031267) with: {'batch_size': 200, 'epochs': 40}\n",
      "0.532556 (0.019240) with: {'batch_size': 200, 'epochs': 60}\n",
      "0.529649 (0.019042) with: {'batch_size': 200, 'epochs': 80}\n",
      "0.554909 (0.055575) with: {'batch_size': 200, 'epochs': 100}\n",
      "21.839468 (0.350358) with: {'batch_size': 250, 'epochs': 5}\n",
      "8.564544 (1.041940) with: {'batch_size': 250, 'epochs': 10}\n",
      "0.572595 (0.015886) with: {'batch_size': 250, 'epochs': 20}\n",
      "0.543275 (0.015850) with: {'batch_size': 250, 'epochs': 40}\n",
      "0.531419 (0.011038) with: {'batch_size': 250, 'epochs': 60}\n",
      "0.548596 (0.038171) with: {'batch_size': 250, 'epochs': 80}\n",
      "0.541198 (0.030430) with: {'batch_size': 250, 'epochs': 100}\n",
      "24.660285 (0.941046) with: {'batch_size': 300, 'epochs': 5}\n",
      "12.195207 (0.791008) with: {'batch_size': 300, 'epochs': 10}\n",
      "0.735936 (0.051898) with: {'batch_size': 300, 'epochs': 20}\n",
      "0.541228 (0.033845) with: {'batch_size': 300, 'epochs': 40}\n",
      "0.535633 (0.025397) with: {'batch_size': 300, 'epochs': 60}\n",
      "0.549244 (0.022163) with: {'batch_size': 300, 'epochs': 80}\n",
      "0.533612 (0.023488) with: {'batch_size': 300, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (abs(mean), stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use scikit-learn to grid search the number of neurons\n",
    "def create_model(neurons=1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    # layer 1\n",
    "    model.add(Dense(9, input_dim=9, activation='relu', kernel_initializer='normal'))\n",
    "    #layer 2\n",
    "    model.add(Dense(neurons, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    #layer 3\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer = 'adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, epochs=100, batch_size=150, verbose=0)\n",
    "# define the grid search parameters\n",
    "neurons = [1, 5, 10, 20, 40, 60, 80, 100]\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.524911 using {'neurons': 60}\n",
      "-4.104506 (0.221393) with: {'neurons': 1}\n",
      "-1.200867 (0.052649) with: {'neurons': 5}\n",
      "-0.692870 (0.085531) with: {'neurons': 10}\n",
      "-0.607553 (0.081301) with: {'neurons': 20}\n",
      "-0.553644 (0.041257) with: {'neurons': 40}\n",
      "-0.524911 (0.027697) with: {'neurons': 60}\n",
      "-0.526432 (0.026803) with: {'neurons': 80}\n",
      "-0.527785 (0.025104) with: {'neurons': 100}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hidden_layers=1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    # layer 1\n",
    "    model.add(Dense(9, input_dim=9, activation='relu',kernel_initializer='normal'))\n",
    "    \n",
    "    #hidden layers\n",
    "    for i in range(hidden_layers):\n",
    "        # Add one hidden layer\n",
    "        model.add(Dense(60, activation='relu',  kernel_initializer='normal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    #layer 4\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer = 'adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, batch_size=150, verbose=0, epochs=100)\n",
    "# define the grid search parameters\n",
    "hidden_layers = [1,2,3,4]\n",
    "param_grid = dict(hidden_layers = hidden_layers)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.541322 using {'hidden_layers': 2}\n",
      "-0.549916 (0.017436) with: {'hidden_layers': 1}\n",
      "-0.541322 (0.022853) with: {'hidden_layers': 2}\n",
      "-0.548761 (0.027697) with: {'hidden_layers': 3}\n",
      "-0.553004 (0.023959) with: {'hidden_layers': 4}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the activation function\n",
    "def create_model(activation='relu'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    # layer 1\n",
    "    model.add(Dense(9, input_dim=9, activation='relu', kernel_initializer='normal'))\n",
    "    #layer 2\n",
    "    model.add(Dense(60, activation=activation,kernel_initializer='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    #layer 3\n",
    "    model.add(Dense(60, activation=activation,kernel_initializer='normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    #layer 4\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer = 'adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, epochs=100, batch_size=150, verbose=0)\n",
    "# define the grid search parameters\n",
    "activation = ['relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.536695 using {'activation': 'linear'}\n",
      "-0.538572 (0.025908) with: {'activation': 'relu'}\n",
      "-0.555273 (0.023452) with: {'activation': 'tanh'}\n",
      "-0.656335 (0.131770) with: {'activation': 'sigmoid'}\n",
      "-0.631365 (0.115903) with: {'activation': 'hard_sigmoid'}\n",
      "-0.536695 (0.025092) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "def create_model(learn_rate=0.01):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    # layer 1\n",
    "    model.add(Dense(9, input_dim=9, activation='relu', kernel_initializer='normal'))\n",
    "    #layer 2\n",
    "    model.add(Dense(60, activation='relu', kernel_initializer='normal'))\n",
    "    #layer 3\n",
    "    model.add(Dense(60, activation='relu',kernel_initializer='normal'))\n",
    "    #layer 4\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    optimizer = Adam(lr=learn_rate)\n",
    "    # Compile model\n",
    "    model.compile(optimizer = optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasRegressor(build_fn=create_model, epochs=100, batch_size=150, verbose=0)\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(learn_rate=learn_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.530466 using {'learn_rate': 0.001}\n",
      "-0.530466 (0.017739) with: {'learn_rate': 0.001}\n",
      "-0.559180 (0.051520) with: {'learn_rate': 0.01}\n",
      "-2.614763 (2.903250) with: {'learn_rate': 0.1}\n",
      "-0.781056 (0.043106) with: {'learn_rate': 0.2}\n",
      "-0.764899 (0.028628) with: {'learn_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
